openai_api_key: "sk-YOUR_OPENAI_KEY"
groq_api_key: 

# --- Service Configurations ---
llm:
  # Models for each provider. The code will pick the right one.
  models:
    openai: "gpt-4o-mini"
    groq: "llama3-8b-8192"
    ollama: "llama3"
  temperature: 0.8
  max_tokens: 200

asr:
  model_size: "base" # "base", "small", "medium", "large-v3"
  device: "cuda"      # "cuda" or "cpu"
  compute_type: "float16" # "float16" for GPU, "int8" for smaller models

memory:
  db_path: "waifu_core/local_db"
  retrieval_results: 3 # How many memories to fetch for context

tts:
  # Coqui TTS Server (for high-quality voice cloning)
  coqui:
    api_url: "http://localhost:5002/api/tts"
    language: "en"
    # The single, high-quality reference file for voice cloning
    reference_voice: "assets/character_voices/ananya_happy.wav"

  # Kokoro TTS (for fast, direct library usage)
  kokoro:
    model_dir: "models/kokoro"
    voice: "af_heart" # A built-in high-quality female voice
    device: "cuda"